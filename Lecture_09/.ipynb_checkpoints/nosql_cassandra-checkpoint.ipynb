{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cassandra and Spark\n",
    "**Andrey Titov**, andrey.titov@bigdatateam.org\n",
    "\n",
    "Big Data Instructor @ BigData Team, http://bigdatateam.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На этом занятии\n",
    "+ Зачем нужны NoSQL\n",
    "+ Теорема CAP Брюера\n",
    "+ Архитектура БД Cassandra\n",
    "+ Модель данных\n",
    "+ Чтение и фильтрация\n",
    "+ Удаление данных\n",
    "+ Запись и изменение данных\n",
    "+ Работа с Cassandra в Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зачем нужны NoSQL\n",
    "\n",
    "NoSQL - термин, описывающий класс БД, имеющих архитектурные отличия от классических реляционных БД.  \n",
    "Основными факторами развития NoSQL БД считаются:\n",
    "- скорость чтения/записи\n",
    "- объем данных\n",
    "- ACID не всегда нужен\n",
    "\n",
    "## Пример\n",
    "Вы проектируете платформу сбора данных с различных датчиков автомобилей всего мира:\n",
    "- критична ли потеря одного события? (нет)\n",
    "- что нам важнее - консистентность данных или доступность системы? (доступность)\n",
    "- будут ли проблемы с сетью? (да)\n",
    "- сколько событий в секунду мы будем обрабатывать? (неизвестно)\n",
    "\n",
    "Для этой задачи нам потребуется БД, которая:\n",
    "- является **гео распределенной**\n",
    "- обеспечивает **доступность данных** при выходе из строя любого узла\n",
    "- продолжает работу при **нарушении сетевой связанности** между любыми узлами\n",
    "- умеет **горизонтально масштабироваться**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теорема CAP Брюера\n",
    "\n",
    "В любой распределенной БД возможно гарантировать выполнение **только двух из трех** свойств:\n",
    "- Consistency\n",
    "- Availability\n",
    "- Partitition tolerance\n",
    "\n",
    "**Consistency**  \n",
    "Результат любого запроса проявляется везде и сразу после того, как мы получили подтверждение от узла о его выполнении\n",
    "  \n",
    "**Availability**  \n",
    "Любая доступная нода должна ответить на запрос\n",
    "\n",
    "**Partition tolerance**  \n",
    "Система продолжает работать в условиях нарушения сетевой связности\n",
    "\n",
    "## И что это означает?\n",
    "\n",
    "**CA системы**  \n",
    "При возникновении проблем все ноды перестают обрабатывать запросы, но зато все консистентно :3\n",
    "\n",
    "**CP системы**  \n",
    "В случае проблем никто не гарантирует доступность данных\n",
    "\n",
    "**AP системы**  \n",
    "Система будет доступна даже после ядерного апокалипсиса, но некоторое время может возвращать не то, что вы ожидаете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура БД Cassandra\n",
    "\n",
    "Cassandra - AP система в теореме CAP. На практике это означает:\n",
    "- высокая доступность данных\n",
    "- нет транзакций (не совсем)\n",
    "- можно строить гео-кластера\n",
    "- слабая согласованность (eventual)\n",
    "- линейная масштабируемость\n",
    "- высокая пропускная способность (особенно на запись)\n",
    "\n",
    "Cassandra имеет симметричную архитектуру. Каждый узел отвечает за хранение данных, обработку запросов и состояние кластера. \n",
    "\n",
    "Расположение данных определяется значением хеш функции от Partition key.\n",
    "\n",
    "Высокая доступность данных обеспечивается за счет репликации.\n",
    "\n",
    "![Cassandra Architecture](https://cassandra.apache.org/doc/latest/_images/ring.svg)\n",
    "Источник: https://cassandra.apache.org/doc/latest/architecture/dynamo.html#dataset-partitioning-consistent-hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import dict_factory\n",
    "from tabulate import tabulate\n",
    "\n",
    "cluster = Cluster(['brain-node1'])\n",
    "session = cluster.connect()\n",
    "session.row_factory = dict_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(data):\n",
    "    print(\n",
    "        tabulate(\n",
    "            data, \n",
    "            tablefmt=\"pretty\", \n",
    "            headers=\"keys\", \n",
    "            showindex=\"always\", \n",
    "            numalign=\"right\", \n",
    "            stralign=\"right\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_keyspace = \\\n",
    "\"\"\"\n",
    "CREATE  KEYSPACE IF NOT EXISTS test \n",
    "WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 3}\n",
    "\"\"\" \n",
    "\n",
    "session.execute(create_keyspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \\\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS test.cars0 (\n",
    "    brand text PRIMARY KEY,\n",
    "    model text,\n",
    "    engine text,\n",
    "    drive_wheel text,\n",
    "    turbo boolean,\n",
    "    acceleration float\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "brands = [\n",
    "  \"Abarth\",\n",
    "  \"Alfa Romeo\",\n",
    "  \"Aston Martin\",\n",
    "  \"Audi\",\n",
    "  \"Bentley\",\n",
    "  \"BMW\",\n",
    "  \"Bugatti\",\n",
    "  \"Cadillac\",\n",
    "  \"Chevrolet\",\n",
    "  \"Chrysler\",\n",
    "  \"Citroën\",\n",
    "  \"Dacia\",\n",
    "  \"Daewoo\",\n",
    "  \"Daihatsu\",\n",
    "  \"Dodge\",\n",
    "  \"Donkervoort\",\n",
    "  \"DS\",\n",
    "  \"Ferrari\",\n",
    "  \"Fiat\",\n",
    "  \"Fisker\",\n",
    "  \"Ford\",\n",
    "  \"Honda\",\n",
    "  \"Hummer\",\n",
    "  \"Hyundai\",\n",
    "  \"Infiniti\",\n",
    "  \"Iveco\",\n",
    "  \"Jaguar\",\n",
    "  \"Jeep\",\n",
    "  \"Kia\",\n",
    "  \"KTM\",\n",
    "  \"Lada\",\n",
    "  \"Lamborghini\",\n",
    "  \"Lancia\",\n",
    "  \"Land Rover\",\n",
    "  \"Landwind\",\n",
    "  \"Lexus\",\n",
    "  \"Lotus\",\n",
    "  \"Maserati\",\n",
    "  \"Maybach\",\n",
    "  \"Mazda\",\n",
    "  \"McLaren\",\n",
    "  \"Mercedes-Benz\",\n",
    "  \"MG\",\n",
    "  \"Mini\",\n",
    "  \"Mitsubishi\",\n",
    "  \"Morgan\",\n",
    "  \"Nissan\",\n",
    "  \"Opel\",\n",
    "  \"Peugeot\",\n",
    "  \"Porsche\",\n",
    "  \"Renault\",\n",
    "  \"Rolls-Royce\",\n",
    "  \"Rover\",\n",
    "  \"Saab\",\n",
    "  \"Seat\",\n",
    "  \"Skoda\",\n",
    "  \"Smart\",\n",
    "  \"SsangYong\",\n",
    "  \"Subaru\",\n",
    "  \"Suzuki\",\n",
    "  \"Tesla\",\n",
    "  \"Toyota\",\n",
    "  \"Volkswagen\",\n",
    "  \"Volvo\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"alpha\",\n",
    "    \"beta\",\n",
    "    \"gamma\",\n",
    "    \"delta\",\n",
    "    \"epsilon\",\n",
    "    \"varepsilon\",\n",
    "    \"zeta\",\n",
    "    \"eta\",\n",
    "    \"theta\",\n",
    "    \"iota\",\n",
    "    \"kappa\",\n",
    "    \"lambda\",\n",
    "    \"mu\",\n",
    "    \"nu\",\n",
    "    \"xi\",\n",
    "    \"omicron\",\n",
    "    \"pi\",\n",
    "    \"rho\",\n",
    "    \"sigma\",\n",
    "    \"tau\",\n",
    "    \"upsilon\",\n",
    "    \"phi\",\n",
    "    \"varphi\",\n",
    "    \"chi\",\n",
    "    \"psi\",\n",
    "    \"omega\"\n",
    "]\n",
    "\n",
    "engines = [\"petrol\", \"diesel\", \"electric\", \"hybrid\"]\n",
    "\n",
    "wheel_drive = [\"rear\", \"front\", \"all\"]\n",
    "\n",
    "turbo = [False, True]\n",
    "\n",
    "acceleration = list(range(3, 20))\n",
    "\n",
    "insert_cars = \\\n",
    "\"\"\"\n",
    "INSERT INTO {keyspace}.{table_name} (brand, model, engine, drive_wheel, turbo, acceleration)\n",
    "VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def write_data(keyspace, table_name, num_rows):\n",
    "    for i in range(0, num_rows):\n",
    "        data = (\n",
    "            random.choice(brands),\n",
    "            random.choice(models),\n",
    "            random.choice(engines),\n",
    "            random.choice(wheel_drive),\n",
    "            random.choice(turbo),\n",
    "            float(random.choice(acceleration))\n",
    "        )\n",
    "        session.execute(insert_cars.format(keyspace=keyspace, table_name=table_name), data)\n",
    "    print(\"Written {n} rows\".format(n=num_rows))\n",
    "    \n",
    "def truncate_table(table_name):\n",
    "    truncate_query = \"TRUNCATE TABLE test.{table_name}\"\n",
    "    session.execute(truncate_query.format(table_name=table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(\"test\", \"cars0\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cars = \\\n",
    "\"\"\"\n",
    "SELECT * FROM test.cars0\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_cars)\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель данных\n",
    "\n",
    "В Cassandra существует три основных типа колонок:\n",
    "- Обычные колонки\n",
    " + опциональны\n",
    " + могут быть иметь любой тип из поддерживаемых\n",
    " + являются nullable\n",
    " + не могут выступать в качестве условия фильтрации\n",
    " + можно добавлять новые и удалять колонки из таблицы\n",
    "- Проиндексированные обычные колонки\n",
    " + могут выступать в качестве условия фильтрации\n",
    "- Partition key\n",
    " + обязателен\n",
    " + порядок (если используется несколько partition key)\n",
    " + одна или несколько колонок\n",
    " + определяет физическое расположение данных на кластере\n",
    " + может выступать в качестве условия фильтрации с предикатами: =, IN\n",
    " + не все типы данных поддерживаются\n",
    "- Clustering key\n",
    " + опционален\n",
    " + одна или несколько колонок\n",
    " + порядок (если используется несколько clustering key) имеет значение\n",
    " + определяет расположение данны внутри партиции\n",
    " + может выступать в качестве условия фильтрации с предикатами =, IN при соблюдении порядка следования*\n",
    " + последний clustering key в запросе может выступать в качестве условия фильтрации с предикатами <, >, !=, =, IN\n",
    " \n",
    "Важно:\n",
    "- строки внутри партиций отсортированы по clustering key\n",
    "- composite key = partition key + clustering key\n",
    "- composite key является уникальным ключом колонки\n",
    "- в одной партиции не может быть более 2kkk строк\n",
    "\n",
    "**Выводы:**\n",
    "- **в реляционных БД модель данных определяется, исходя из структуры данных**\n",
    "- **в Cassandra модель данных определяется, исходя из запросов к данным**\n",
    "- **В Cassandra данные обычно хранят в денормализованном виде**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение и фильтрация\n",
    "Partition key может выступать условием с предикатами =, IN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars0 WHERE brand = 'Audi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars0 WHERE brand IN ('Audi', 'BMW')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтровать данные по обычной колонке нельзя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars0 WHERE drive_wheel = 'front'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но если очень хочется, то можно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В большинстве случаев, использование ALLOW FILTERING - это антипаттерн\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars0 WHERE drive_wheel = 'front' ALLOW FILTERING\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к DDL таблицы cars0:\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS test.cars0 (\n",
    "    brand text PRIMARY KEY,\n",
    "    model text,\n",
    "    engine text,\n",
    "    drive_wheel text,\n",
    "    turbo boolean,\n",
    "    acceleration float\n",
    ")\n",
    "```\n",
    "\n",
    "В данной таблице только одна колонка является единственным partition key - `brand`. Поэтому, сколько бы мы данных не записали, количество строк в таблице будет ограничено размером массива `brands`, остальные строки будут перезаписываться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При необходимости мы можем очистить таблицу cars0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_table(\"cars0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и наполним новую таблицу cars1, в которой ключами будут две колонки `brand` и `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \\\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS test.cars1 (\n",
    "    brand text,\n",
    "    model text,\n",
    "    engine text,\n",
    "    drive_wheel text,\n",
    "    turbo boolean,\n",
    "    acceleration float, PRIMARY KEY (brand, model)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table)\n",
    "truncate_table(\"cars1\")\n",
    "write_data(\"test\", \"cars1\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем все данные из этой таблицы и убедимся, что их больше `len(brands)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cars = \\\n",
    "\"\"\"\n",
    "SELECT * FROM test.cars1;\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_cars)\n",
    "print(\"Table contains {n} rows and brands has length of {m}\".format(n=len(list(rows)), m=len(brands)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем первые 5 строк на экран. Красным цветом выделен partition key, голубым - clustering key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars1 LIMIT 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтровать данные запросы здесь можно:\n",
    "- по полю `brand`\n",
    "- по полю `brand` и полю `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars1 WHERE brand = 'Chrysler' LIMIT 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars1 WHERE brand = 'Chrysler' AND model = 'alpha'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтровать данные только по полю `model` нельзья:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars1 WHERE model = 'alpha'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим еще одну таблицу, используя колонки `brand`, `model`, `engine`, `acceleration` в качестве ключей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \\\n",
    "\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS test.cars2 (\n",
    "    brand text,\n",
    "    model text,\n",
    "    engine text,\n",
    "    drive_wheel text,\n",
    "    turbo boolean,\n",
    "    acceleration float, PRIMARY KEY ((brand, model), engine, acceleration)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table)\n",
    "truncate_table(\"cars2\")\n",
    "write_data(\"test\", \"cars2\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cars = \\\n",
    "\"\"\"\n",
    "SELECT * FROM test.cars2;\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_cars)\n",
    "print(\"Table contains {n} rows\".format(n=len(list(rows))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим структуру ключей в таблице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 LIMIT 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможные варианты фильтрации:\n",
    "- по колонкам `brand`, `model`\n",
    "- по колонкам `brand`, `model`, `engine`,\n",
    "- по колонка `brand`, `model`, `engine`, `acceleration`\n",
    "\n",
    "Важно:\n",
    "- фильтрация по колонкам `brand` и `model` возможна только используя условия = и IN\n",
    "- фильтровать <, >, != можно только по последнему кластерному ключу в запросе\n",
    "\n",
    "Таким образом, работать будут следующие запросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' and engine = 'electric'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \\\n",
    "    \"SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' and engine = 'electric' \\\n",
    "    AND acceleration > 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запросы ниже работать не будут:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE model = 'phi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE engine = 'electric'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \\\n",
    "    \"SELECT * FROM test.cars2 WHERE brand = 'Volvo' and model = 'phi' \\\n",
    "    AND acceleration > 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- структура таблицы в БД зависит от запросов к ней\n",
    "- нельзя пропускать (слева направо) ключи при фильтрации, но можно опустить последние n кластерных ключей\n",
    "- нельзя фильтровать по одному из partition keys\n",
    "- нельзя фильтровать по обычным колонкам (если она не проиндексирована)\n",
    "- фильтровать c использованием <, >, != можно только по последнему кластерному ключу в запросе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Удаление данных\n",
    "Для изучения запросов на удаление данных будем использовать таблицу `cars2`\n",
    "Для начала, добавим в нее данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(\"test\", \"cars0\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi' \\\n",
    "    AND engine = 'diesel' AND acceleration > 1\"\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi' \\\n",
    "    AND engine = 'petrol'\"\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"DELETE FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\"\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- удалять можно одну строку, указав весь composite key\n",
    "- удалять можно группу строк, указав все partition key и часть clustering key\n",
    "- удалять можно партицию целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запись и изменение данных\n",
    "Для изучения запросов на удаление данных будем использовать таблицу `cars2`\n",
    "Для начала, добавим в нее данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(\"test\", \"cars2\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"INSERT INTO test.cars2 (brand, model, engine, acceleration, drive_wheel, turbo) \\\n",
    "    VALUES ('Audi', 'pi', 'electric', -1, 'all', false)\"\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cqlsh brain-node1 -e \"UPDATE test.cars2 SET turbo = true \\\n",
    "    WHERE brand = 'Audi' AND model = 'pi' AND engine = 'electric' AND acceleration = -1\"\n",
    "!cqlsh brain-node1 -e \"SELECT * FROM test.cars2 WHERE brand = 'Audi' AND model = 'pi'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- под капотом INSERT и UPDATE являются единой операцией, которая называется UPSERT\n",
    "- при использовании INSERT и UPDATE единственным требованием является указание всего composite key\n",
    "- используя стандартный SELECT, INSERT и UPDATE, нельзя обеспечить атомарное изменение поля строки (см. LWT https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useInsertLWT.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark cassandra connector\n",
    "\n",
    "https://github.com/datastax/spark-cassandra-connector\n",
    "\n",
    "Для работы с Cassandra в Spark необходимо добавить:\n",
    "```\n",
    "--packages com.datastax.spark:spark-cassandra-connector_2.11:2.4.3 \\\n",
    "--conf spark.cassandra.connection.host=brain-node1 \\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.read \\\n",
    "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "            .options(table=\"cars0\", keyspace=\"test\") \\\n",
    "            .load()\n",
    "    \n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяя фильтр, следует помнить о структуре ключей. Если фильтр составлен правильном, то сработает predicate pushdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p = df.filter(col(\"brand\") == \"Audi\")\n",
    "filtered_p.explain(True)\n",
    "filtered_p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicate pushdown сработает и в этом случае, но под капотом будет использован ALLOW FILTERING, т.к. фильтрация осуществляется не по ключу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p = df.filter(col(\"engine\") == \"petrol\")\n",
    "filtered_p.explain(True)\n",
    "filtered_p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, если сделать более сложный фильтр, то predicate pyshdown не произойдет. В этом случае spark прочитает таблицу ЦЕЛИКОМ. Это следует помнить при работе с большими таблицами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p = df.filter(length(col(\"brand\")) > 4)\n",
    "filtered_p.explain(True)\n",
    "filtered_p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись осуществляется по аналогии с другими форматами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p \\\n",
    "    .write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"cars1\", keyspace=\"test\").mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full List of Predicate Pushdown Restrictions\n",
    "\n",
    "1. Only push down no-partition key column predicates with =, >, <, >=, <= predicate\n",
    "2. Only push down primary key column predicates with = or IN predicate.\n",
    "3. If there are regular columns in the pushdown predicates, they should have\n",
    "   at least one EQ expression on an indexed column and no IN predicates.\n",
    "4. All partition column predicates must be included in the predicates to be pushed down,\n",
    "   any part of the partition key can be an EQ or IN predicate. For each partition column,\n",
    "   only one predicate is allowed.\n",
    "5. For cluster column predicates, only last predicate can be RANGE predicate\n",
    "   and preceding column predicates must be EQ or IN predicates.\n",
    "   If there is only one cluster column predicate, the predicates could be EQ or IN or RANGE predicate.\n",
    "6. There is no pushdown predicates if there is any OR condition or NOT IN condition.\n",
    "7. We're not allowed to push down multiple predicates for the same column if any of them\n",
    "   is equality or IN predicate.\n",
    "   \n",
    "https://github.com/datastax/spark-cassandra-connector/blob/master/doc/14_data_frames.md#full-list-of-predicate-pushdown-restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- используя cassandra в spark, следует помнить о структуре композитного ключа и особенностях составления запросов к БД\n",
    "- конфигурация БД указывается в параметрах `spark-submit` при запуске приложения\n",
    "- для работы с Cassandra необходимо добавить зависимость с https://mvnrepository.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop\n",
    "\n",
    "Эффективность работы Cassandra в проекте напрямую зависит от структуры таблиц. Перед тем как создавать таблицы, вам необходимо понять, какие запросы будут делать пользователи. На этом семинаре вам нужно подготовить данные, загрузить их в БД и ответить на вопросы ниже\n",
    "\n",
    "Датасет: https://datahub.io/core/airport-codes#resource-airport-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df = spark.read.csv(path=\"/tmp/airport-codes.csv\", header=True)\n",
    "df.printSchema()\n",
    "print(\"#\" * 20)\n",
    "print(\"There are {c} airports in the dataset\".format(c=df.count()))\n",
    "print(\"#\" * 20)\n",
    "df.show(1, 200, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "В Сassandra все таблицы сгруппированы по KEYSPACE'ам. На уровне KEYSPACE'а устанавливаются важный параметр - фактор репликации данных в таблице. В случае геораспределенных инсталляций фактор репликации задается для каждого датацентра отдельно.\n",
    "\n",
    "Создайте KEYSPACE с именем **вашего пользователя** с параметром `REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 3}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(col(\"iso_country\") == \"RU\").groupBy(\"iso_region\").count().show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вам нужно создать таблицу и загрузить в нее данные. Тут есть несколько моментов:\n",
    "- данные необходимо почистить и предобработать:\n",
    " + разбить coordinates на 2 колонки и преобразовать во float: первое значение это longitude, второе - lattitude\n",
    " + структура ключей будет такая: `((iso_country, iso_region), ident)` - кортеж iso_country и iso_region это partition key, а ident - clustrering key. Перед записью данных в БД нам нужно убедиться, что среди ключей нет null и что кортеж (iso_country, iso_region, ident) не имеет дубликатов в датасете, иначе мы не сможем использовать его в качестве ключа\n",
    "- готовить и записывать данные удобнее с помощью Spark. При записи вам нужно обеспечить соответствие имен и типов полей DF полям таблицы\n",
    "\n",
    "Создайте таблицу `airports_plain` в вашем keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните предобработку данных и запишите их в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2\n",
    "\n",
    "Прочитайте таблицу с помощью `spark`. Выведите первые 20 строк на экран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторите операцию, используя `cqlsh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторите операцию, используя библиотеку `cassandra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран 20 аэропортов, расположенных в `iso_country = RU` и `iso_region = RU-MOW`. Выполните эту операцию с помощью `spark`, `cassandra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран 20 аэропортов, у которых `elevation_ft > 100`. Выполните эту операцию с помощью `spark`, `cassandra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран 20 аэропортов, у которых значение `name` начинается с буквы `T`. Выполните эту операцию с помощью `spark`, `cassandra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основании выполненных экспериментов вы должны сделать следующие выводы:\n",
    "- Пока запрос \"укладывается\" в структуру таблицы,  Cassandra будет отдавать данные очень быстро при использовании обычной библиотеки (не spark). Даже если речь будет идти о десятках тысячах запросов в секунду, БД справиться с этой задачей.\n",
    "- Если запрос не \"укладывается\" в структуру, то у вас есть вариант использовать `ALLOW FILTERING`. Но здесь у вас будет деградация скорости выполнения запросов и избыточная нагрузка на базу.\n",
    "- Если запрос не укладывается в ограничения синтаксиса CQL, то вашим единственным вариантом является прочитать большой объем данных из таблицы и затем обработать их. Именно это и делает за вас `spark` в третьем эксперименте. Однако, запустить большое количество одновременных запросов к базе с помощью `spark` не получится - база не сможет отдавать данные с такой скоростью. В этом от части и состоит прелесть Cassandra - при должном проектировании вы можете совмещать разные типы нагрузок и одновременно использовать ее для высоконагруженного бекенд сервиса и выполнять OLAP анализ данных на одних и тех же данных. В случае с HDFS такое возможным не представляется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3\n",
    "\n",
    "Спроектируйте таблицу (таблицы) и наполните их данными так, чтобы максимально быстро отвечать на запрос:\n",
    "\"Вывести список аэропортов, расположенных на расстоянии не более `max_longitude_dist` по долготе и `max_lattitude_dist` по широте\". \n",
    "\n",
    "Напишите функцию, которая позволяет ответить на данный запрос. Данная функция принимает текущие координаты объекта (например, у нас летит самолет и ему надо срочно где-то выполнить посадку) и максимальное расстояние по долготе и широте. Функция должна возвращать список словарей с данными об аэропортах.\n",
    "\n",
    "P.S. Для решения это задачи можете использовать как библиотеку `cassandra`, так и `spark`, но данная функция должна работать макисмально быстро.\n",
    "\n",
    "P.P.S. Не всегда нужно хранить данные в одной таблице. Помните, в Cassandra таблицы делаются под запросы и денормализация данных - это нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_airports(current_longitude, current_lattitude, max_longitude_dist, max_lattitude_dist):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
